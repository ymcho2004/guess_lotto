from fastapi import FastAPI, Query
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from sklearn.preprocessing import MinMaxScaler
import copy
from fastapi.middleware.cors import CORSMiddleware

# --- ëª¨ë¸ êµ¬ì¡° (ë³€ë™ ì—†ìŒ) ---
class LottoLSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers, output_size):
        super(LottoLSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)
        self.fc = nn.Linear(hidden_size, output_size)

    def forward(self, x):
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        out, _ = self.lstm(x, (h0, c0))
        out = self.fc(out[:, -1, :])
        return out

app = FastAPI()

origins = [
    "http://localhost:5173", # ë¦¬ì•¡íŠ¸ ê°œë°œ ì„œë²„ ì£¼ì†Œ
    "http://127.0.0.1:5173",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ëª¨ë¸ ë¡œë“œ
device = torch.device('cpu')
model = LottoLSTM(input_size=6, hidden_size=128, num_layers=2, output_size=6)
try:
    model.load_state_dict(torch.load("lotto_lstm.pth", map_location=device))
except:
    print("ëª¨ë¸ íŒŒì¼ì´ ì—†ì–´ìš”!")
model.eval()

# ë°ì´í„° ë¡œë“œ
df = pd.read_csv("lotto_history.csv")
scaler = MinMaxScaler()
scaler.fit_transform(df[['drwtNo1', 'drwtNo2', 'drwtNo3', 'drwtNo4', 'drwtNo5', 'drwtNo6']].values)

@app.get("/")
def read_root():
    return {"message": "ğŸ° ë¡œë˜ ì˜ˆì¸¡ AI (Deterministic Mode) ğŸ°"}

@app.get("/predict")
def predict_lotto(count: int = Query(5, ge=1, le=10)): 
    last_5_games = df.tail(5)[['drwtNo1', 'drwtNo2', 'drwtNo3', 'drwtNo4', 'drwtNo5', 'drwtNo6']].values
    input_data = scaler.transform(last_5_games)
    
    recommended_sets = []
    
    # ì‹œë“œ ê³ ì • (ìƒˆë¡œê³ ì¹¨í•´ë„ ê²°ê³¼ ìœ ì§€)
    np.random.seed(42) 

    # --- AIê°€ ëê¹Œì§€ ì±…ì„ì§€ëŠ” í•¨ìˆ˜ ---
    def get_ai_numbers(base_input, noise_level=0.0):
        # 1. ì…ë ¥ ë°ì´í„° ì¤€ë¹„ (ë…¸ì´ì¦ˆ ì¶”ê°€)
        noise = np.random.normal(0, noise_level, base_input.shape)
        noisy_input = base_input + noise
        input_tensor = torch.tensor(noisy_input, dtype=torch.float32).unsqueeze(0).to(device)
        
        # 2. ëª¨ë¸ ì˜ˆì¸¡
        with torch.no_grad():
            prediction = model(input_tensor)
        
        # 3. ê²°ê³¼ ë³€í™˜ (ì‹¤ìˆ˜ -> ì •ìˆ˜ ë¦¬ìŠ¤íŠ¸)
        pred_nums = scaler.inverse_transform(prediction.numpy())
        result = np.round(pred_nums).astype(int)[0]
        result = np.clip(result, 1, 45)
        return result.tolist() # ìˆœìˆ˜ íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë°˜í™˜

    # --- ì‚¬ìš©ìê°€ ìš”ì²­í•œ ì„¸íŠ¸ ìˆ˜ë§Œí¼ ë°˜ë³µ ---
    for i in range(count):
        # ì²« ë²ˆì§¸ ì„¸íŠ¸ëŠ” ë…¸ì´ì¦ˆ ì—†ì´(ìˆœìˆ˜ ì‹¤ë ¥), ê·¸ ë’¤ë¡œëŠ” ë…¸ì´ì¦ˆ ì„ì–´ì„œ
        current_noise = 0.0 if i == 0 else 0.05
        
        # 1. ì¼ë‹¨ AIí•œí…Œ ë¬¼ì–´ë´„
        ai_picks = get_ai_numbers(input_data, noise_level=current_noise)
        
        # 2. ì¤‘ë³µ ì œê±°
        unique_picks = sorted(list(set(ai_picks)))
        
        # 3. [í•µì‹¬] 6ê°œê°€ ì•ˆ ë˜ë©´? AIí•œí…Œ ê³„ì† ë‹¤ì‹œ ë¬¼ì–´ë´ì„œ ì±„ì›€!
        attempts = 0
        while len(unique_picks) < 6:
            attempts += 1
            # "ì•¼, ë‹¤ë¥¸ ê°ë„ë¡œ ë‹¤ì‹œ ìƒê°í•´ ë´" (ë…¸ì´ì¦ˆë¥¼ ì¡°ê¸ˆì”© ë‹¤ë¥´ê²Œ ì¤Œ)
            # attemptsê°€ ëŠ˜ì–´ë‚ ìˆ˜ë¡ ë…¸ì´ì¦ˆë¥¼ ì¡°ê¸ˆì”© í‚¤ì›Œì„œ ìƒˆë¡œìš´ ìˆ«ìë¥¼ ìœ ë„í•¨
            retry_noise = current_noise + (attempts * 0.02)
            
            backup_picks = get_ai_numbers(input_data, noise_level=retry_noise)
            
            for num in backup_picks:
                if num not in unique_picks:
                    unique_picks.append(num)
                    if len(unique_picks) == 6:
                        break
            
            # (í˜¹ì‹œë‚˜ ë¬´í•œë£¨í”„ ë°©ì§€ìš© ì•ˆì „ì¥ì¹˜ - 100ë²ˆ ë¬¼ì–´ë´ë„ ì—†ìœ¼ë©´ ê·¸ë•ŒëŠ” í¬ê¸°..í•˜ì§€ë§Œ ê·¸ëŸ´ ì¼ ì—†ìŒ)
            if attempts > 100:
                break
        
        recommended_sets.append(sorted(unique_picks))
    
    return {
        "count": count,
        "predictions": recommended_sets
    }